{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e2f5acd-4b15-4f5c-9e37-9f607c159512",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,DataCollatorWithPadding, TrainingArguments,Trainer\n",
    "import torch\n",
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "import numpy as np\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee1d2805-3798-4bc1-8ac5-80291d717dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2395db9d-290d-475c-9a25-d9f9bf5d2e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "id2label = {0:\"Negative\",1:\"Positive\"}\n",
    "label2id = {\"Negative\":0, \"Positive\":1}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint,num_labels = 2, id2label=id2label, label2id = label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778ec2c4-4bbb-43ec-a273-f9946cdb89f8",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6ad65aa-0775-4e88-8e6c-8d00f550fdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1be58fd-1c72-4102-8420-d5b5e5cc4831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('shawhin/imdb-truncated')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f52709c-6bfe-4a87-82bf-3860b5e0e533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'. . . or type on a computer keyboard, they\\'d probably give this eponymous film a rating of \"10.\" After all, no elephants are shown being killed during the movie; it is not even implied that any are hurt. To the contrary, the master of ELEPHANT WALK, John Wiley (Peter Finch), complains that he cannot shoot any of the pachyderms--no matter how menacing--without a permit from the government (and his tone suggests such permits are not within the realm of probability). Furthermore, the elements conspire--in the form of an unusual drought and a human cholera epidemic--to leave the Wiley plantation house vulnerable to total destruction by the Elephant People (as the natives dub them) to close the story. If you happen to see the current release EARTH, you\\'ll detect the Elephant People are faring less well today.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0964d87f-a9de-4b7e-a316-c15f91ce7add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(dataset['train']['label']).sum()/len(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073cf93c-acbe-46d6-8dca-ee41e905b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the distillbert tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint,add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "821744d5-d231-4ec7-9913-636e01cce258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding pad token if none exists\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token':'[PAD]'})\n",
    "    model.resize_token_embedings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cbe17c3-85dd-40ed-85c3-415e8c247bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 7592, 1010, 2129, 2024, 2017, 1029, 102], [101, 1045, 2572, 2986, 1010, 4067, 2017, 999, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\"Hello, how are you?\", \"I am fine, thank you!\"]\n",
    "input_sentence = tokenizer(sentences)\n",
    "input_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "675f9f91-d7e0-42e9-aac8-6a90616c9c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 7592, 1010, 2129, 2024, 2017, 1029,  102,    0],\n",
       "        [ 101, 1045, 2572, 2986, 1010, 4067, 2017,  999,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_inputs_padded = tokenizer(sentences,padding=True,truncation=True,return_tensors = \"pt\")\n",
    "tokenized_inputs_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7e9fade-8f01-427e-9c2e-6c95ee223518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe76a46be73243a8a53762e31dc26095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    text = examples['text']\n",
    "    tokenizer.truncation_size = \"left\"\n",
    "    tokenized_inputs = tokenizer(text,return_tensors=\"np\",truncation=True,max_length = 512)\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched = True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72047be6-37de-4b49-96e9-53ff884f91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating data collator \n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d7ec1c-b14c-4308-8603-9b7c0f0e08f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lora config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2689748c-ead0-43c0-8549-82dc8dc8dee6",
   "metadata": {},
   "source": [
    "## LORA Config\n",
    "\n",
    "Type of Task= Sequence Classification\r\n",
    "\r\n",
    "r= Rank in LoRA which defines the trainable weight matrix\r\n",
    "\r\n",
    "Alpha, dropout= We have the learning rate and dropout rate\r\n",
    "\r\n",
    "Target= define the layer to which we apply the Lora- in our case we apply to the linear query layer\r\n",
    "\r\n",
    "Hence we set up a LoRA adapter for parameter-efficient fine-tuning of a base model for a sequence classification task. It focuses on adapting only the q_lin module ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6875d3ea-5927-406f-a3f0-97aa23b46a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",r=4, lora_alpha=32, lora_dropout=0.01,target_modules=['q_lin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd6f7682-ab7a-4765-9772-f84c04de45d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9307\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model,peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb402af-305d-47b2-b285-a5b3713d6640",
   "metadata": {},
   "source": [
    "## Sample Resutls on the pretrained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8949c8c4-996e-4bcc-aafe-0b1c6e0d0091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was good. - Negative\n",
      "Not a fan, don't recommend. - Negative\n",
      "Better than the first one. - Negative\n",
      "This is not worth watching even once. - Negative\n",
      "This one is a pass. - Negative\n"
     ]
    }
   ],
   "source": [
    "# Define the examples to infer\n",
    "text_list = [\"It was good.\",\"Not a fan, don't recommend.\",\"Better than the first one.\",\"This is not worth watching even once.\",\"This one is a pass.\"]\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text,return_tensors='pt')\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.argmax(logits)\n",
    "\n",
    "    print(text+\" - \"+ id2label[predictions.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a09a86-be28-41c1-87ad-4e7a4b356495",
   "metadata": {},
   "source": [
    "## Evaluating a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af09bd24-0832-46e3-8a83-0a97fc37b5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52f5eac6-40de-4239-b1a3-1651149badf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions, references=labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63165a-7ad0-4454-9fd6-ca8d9fd6c21c",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "473ce24f-1cd9-4ca3-b3d1-f6f6ead52036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "497cfc3d-c106-4044-b5e6-5e7769b42786",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "batch_size = 4\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f90ac61-3178-45d7-b076-6130dc7c9153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\transformers\\training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define trainable arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = model_checkpoint + \"lora-text-classification\",\n",
    "    learning_rate = lr,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    num_train_epochs = num_epochs,\n",
    "    weight_decay = 0.01,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    load_best_model_at_end = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "167a0c17-04fa-4805-9fbf-eeff2e8fc0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5000/5000 07:22, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.436604</td>\n",
       "      <td>{'accuracy': 0.886}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.599062</td>\n",
       "      <td>{'accuracy': 0.874}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.336100</td>\n",
       "      <td>0.762921</td>\n",
       "      <td>{'accuracy': 0.882}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.207600</td>\n",
       "      <td>0.897397</td>\n",
       "      <td>{'accuracy': 0.874}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.207600</td>\n",
       "      <td>1.078079</td>\n",
       "      <td>{'accuracy': 0.871}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>1.028684</td>\n",
       "      <td>{'accuracy': 0.873}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>1.333653</td>\n",
       "      <td>{'accuracy': 0.872}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>1.298608</td>\n",
       "      <td>{'accuracy': 0.878}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>1.095446</td>\n",
       "      <td>{'accuracy': 0.882}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>1.318514</td>\n",
       "      <td>{'accuracy': 0.874}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.062900</td>\n",
       "      <td>1.463235</td>\n",
       "      <td>{'accuracy': 0.872}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.313723</td>\n",
       "      <td>{'accuracy': 0.888}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.581585</td>\n",
       "      <td>{'accuracy': 0.869}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>1.564720</td>\n",
       "      <td>{'accuracy': 0.875}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>1.490902</td>\n",
       "      <td>{'accuracy': 0.88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>1.468513</td>\n",
       "      <td>{'accuracy': 0.878}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>1.435302</td>\n",
       "      <td>{'accuracy': 0.886}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.440190</td>\n",
       "      <td>{'accuracy': 0.883}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>1.484250</td>\n",
       "      <td>{'accuracy': 0.88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.487566</td>\n",
       "      <td>{'accuracy': 0.88}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinci\\miniconda3\\envs\\vinci\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5000, training_loss=0.09064136281013489, metrics={'train_runtime': 442.6766, 'train_samples_per_second': 45.18, 'train_steps_per_second': 11.295, 'total_flos': 2227175752044000.0, 'train_loss': 0.09064136281013489, 'epoch': 20.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the trainer object\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_dataset[\"train\"],\n",
    "    eval_dataset = tokenized_dataset[\"validation\"],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea552ed4-194e-4b7b-b438-812ab9e0d87c",
   "metadata": {},
   "source": [
    "## Infering the fine tuned model with an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09f2fe7e-22d8-421f-ac35-ee560c3ff041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was good. - Positive\n",
      "Not a fan, don't recommend. - Negative\n",
      "Better than the first one. - Positive\n",
      "This is not worth watching even once. - Negative\n",
      "This one is a pass. - Positive\n"
     ]
    }
   ],
   "source": [
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text,return_tensors=\"pt\").to(\"cuda\")\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits,1).indices\n",
    "    print(text + \" - \" + id2label[predictions.tolist()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903a8860-a9bb-4a4f-a414-cfacaf1fc181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
